{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapid Prototype Solution (With Generative AI Tools):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Step 1: Install Required Libraries\n",
    "\n",
    "**pip install lightfm pandas numpy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightfm pandas numpy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Step 2: Load Your Dataset (events.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       timestamp  visitorid event  itemid  transactionid\n",
      "0  1433221332117     257597  view  355908            NaN\n",
      "1  1433224214164     992329  view  248676            NaN\n",
      "2  1433221999827     111016  view  318965            NaN\n",
      "3  1433221955914     483717  view  253185            NaN\n",
      "4  1433221337106     951259  view  367447            NaN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "events = pd.read_csv(\"data/events.csv\")\n",
    "\n",
    "# Display first few rows\n",
    "print(events.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Step 3: Convert Data for LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "# Initialize LightFM dataset\n",
    "dataset = Dataset()\n",
    "\n",
    "# Fit dataset with unique users and items\n",
    "dataset.fit(users=events[\"visitorid\"].unique(), items=events[\"itemid\"].unique())\n",
    "\n",
    "# Build interaction matrix (assuming each event counts as an interaction)\n",
    "(interactions, weights) = dataset.build_interactions(\n",
    "    (row[\"visitorid\"], row[\"itemid\"]) for _, row in events.iterrows()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Step 4: Train a Simple Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1281e2a90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = LightFM(loss=\"warp\")  # WARP optimizes ranking\n",
    "\n",
    "# Train model for 10 epochs\n",
    "model.fit(interactions, epochs=10, num_threads=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¹ Step 5: Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended items: [247909, 153778, 65273, 315545, 253615, 384302, 434782, 88886, 392074, 299677]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def recommend_items(model, dataset, user_id, n=5):\n",
    "    \"\"\"Recommend top N items for a given user.\"\"\"\n",
    "    n_users, n_items = dataset.interactions_shape()\n",
    "    \n",
    "    # Predict scores for all items\n",
    "    scores = model.predict(user_id, np.arange(n_items))\n",
    "    \n",
    "    # Get top N items\n",
    "    top_items = np.argsort(-scores)[:n]\n",
    "    \n",
    "    # Map back to item IDs\n",
    "    item_mapping = list(dataset.mapping()[2].keys())\n",
    "    recommended_items = [item_mapping[i] for i in top_items]\n",
    "    \n",
    "    return recommended_items\n",
    "\n",
    "# Example: Get recommendations for user ID 257597\n",
    "print(\"Recommended items:\", recommend_items(model, dataset, user_id=0, n=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming events is your data with columns: user_id, item_id, and interaction value\n",
    "\n",
    "# 1. Create LightFM dataset\n",
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    users=events['user_id'].unique(),\n",
    "    items=events['item_id'].unique()\n",
    ")\n",
    "\n",
    "# 2. Create interaction matrix\n",
    "interactions, weights = dataset.build_interactions(\n",
    "    ((row['user_id'], row['item_id']) for idx, row in events.iterrows())\n",
    ")\n",
    "\n",
    "# 3. Split data into train and test\n",
    "train_interactions, test_interactions = train_test_split(\n",
    "    interactions, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Create and train model\n",
    "model = LightFM(learning_rate=0.05, loss='warp')\n",
    "model.fit(\n",
    "    train_interactions,\n",
    "    epochs=30,\n",
    "    num_threads=2  # Adjust based on your CPU\n",
    ")\n",
    "\n",
    "# 5. Evaluate precision\n",
    "def evaluate_lightfm_precision(model, test_interactions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate precision@k for LightFM model\n",
    "    \"\"\"\n",
    "    precision = precision_at_k(\n",
    "        model, \n",
    "        test_interactions, \n",
    "        k=k\n",
    "    ).mean()\n",
    "    \n",
    "    print(f\"Precision@{k}: {precision:.4f}\")\n",
    "    return precision\n",
    "\n",
    "# 6. Get precision score\n",
    "precision_score = evaluate_lightfm_precision(model, test_interactions, k=10)\n",
    "\n",
    "# Optional: Generate recommendations for a specific user\n",
    "def get_recommendations(model, user_id, item_ids, n_items=10):\n",
    "    scores = model.predict(user_id, item_ids)\n",
    "    top_items = item_ids[np.argsort(-scores)[:n_items]]\n",
    "    return top_items\n",
    "\n",
    "# Example of getting recommendations for user 1:\n",
    "# user_items = get_recommendations(model, 1, np.arange(n_items), n_items=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
