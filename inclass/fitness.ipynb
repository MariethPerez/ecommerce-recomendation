{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Problem A: Class Attendance Prediction (using ./data/problem2.csv) ---\n",
      "Problem A data (./data/problem2.csv) loaded successfully.\n",
      "Cleaning 'days_before' column...\n",
      "'days_before' column cleaned and converted to numeric.\n",
      "Data split complete for Problem A: Train set size=1200, Test set size=300\n",
      "\n",
      "Training Logistic Regression (Problem A)...\n",
      "Training Random Forest Classifier (Problem A)...\n",
      "Model training complete for Problem A.\n",
      "\n",
      "--- Evaluating Classification Models (Problem A) ---\n",
      "\n",
      "Logistic Regression Performance (Problem A):\n",
      "Accuracy: 0.7733\n",
      "ROC AUC: 0.8288\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83       209\n",
      "           1       0.61      0.73      0.66        91\n",
      "\n",
      "    accuracy                           0.77       300\n",
      "   macro avg       0.74      0.76      0.75       300\n",
      "weighted avg       0.79      0.77      0.78       300\n",
      "\n",
      "\n",
      "Random Forest Classifier Performance (Problem A):\n",
      "Accuracy: 0.7533\n",
      "ROC AUC: 0.7802\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83       209\n",
      "           1       0.60      0.56      0.58        91\n",
      "\n",
      "    accuracy                           0.75       300\n",
      "   macro avg       0.71      0.70      0.70       300\n",
      "weighted avg       0.75      0.75      0.75       300\n",
      "\n",
      "\n",
      "\n",
      "--- Starting Problem B: Gym Crowdedness Prediction (using ./data/problem1.csv) ---\n",
      "Problem B data (./data/problem1.csv) loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v7/pz5_q5x958gblydndglhwrw00000gp/T/ipykernel_90458/3646121268.py:128: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df_problem_B['date'] = pd.to_datetime(df_problem_B['date'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split complete for Problem B: Train set size=49747, Test set size=12437\n",
      "\n",
      "Training Linear Regression (Problem B)...\n",
      "Training Random Forest Regressor (Problem B)...\n",
      "Model training complete for Problem B.\n",
      "\n",
      "--- Evaluating Regression Models (Problem B) ---\n",
      "\n",
      "Linear Regression Performance (Problem B):\n",
      "RMSE (Root Mean Squared Error): 15.8244\n",
      "R^2 Score: 0.5155\n",
      "\n",
      "Random Forest Regressor Performance (Problem B):\n",
      "RMSE (Root Mean Squared Error): 6.4871\n",
      "R^2 Score: 0.9186\n",
      "\n",
      "--- Feature Importance Analysis (Problem B - Random Forest Regressor) ---\n",
      "Could not extract feature importances automatically: 'ColumnTransformer' object has no attribute 'named_steps'\n",
      "Feature importances are available in rf_model_reg.feature_importances_ but matching names requires care.\n",
      "\n",
      "\n",
      "--- Analysis Complete ---\n",
      "Next steps would involve deeper EDA, feature engineering, hyperparameter tuning, model selection, and crucial ethical considerations review.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import re # Import regular expressions module\n",
    "\n",
    "# --- Problem A: Optimizing Group Fitness Class Utilization (Classification) ---\n",
    "# --- USES data from ./data/problem2.csv BASED ON PROVIDED COLUMN NAMES ---\n",
    "\n",
    "print(\"--- Starting Problem A: Class Attendance Prediction (using ./data/problem2.csv) ---\")\n",
    "\n",
    "# 1. Load Data for Problem A (Classification)\n",
    "data_path_A = './data/problem2.csv' # Updated path\n",
    "try:\n",
    "    df_problem_A = pd.read_csv(data_path_A)\n",
    "    print(f\"Problem A data ({data_path_A}) loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {data_path_A} not found. Please ensure the 'data' folder exists and contains the file.\")\n",
    "    exit()\n",
    "\n",
    "# ****** START OF CLEANING STEP ******\n",
    "# Clean the 'days_before' column: Extract number from string like 'X days'\n",
    "def extract_days(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.search(r'\\d+', value) # Find one or more digits\n",
    "        if match:\n",
    "            return int(match.group(0))\n",
    "    elif pd.isna(value):\n",
    "         return np.nan # Keep NaN as NaN for imputer\n",
    "    elif isinstance(value, (int, float)):\n",
    "         return int(value) # Keep existing numbers as numbers\n",
    "    return np.nan # Return NaN if format is unexpected\n",
    "\n",
    "print(\"Cleaning 'days_before' column...\")\n",
    "try:\n",
    "    df_problem_A['days_before'] = df_problem_A['days_before'].apply(extract_days)\n",
    "    df_problem_A['days_before'] = pd.to_numeric(df_problem_A['days_before'], errors='coerce')\n",
    "    print(\"'days_before' column cleaned and converted to numeric.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cleaning 'days_before': {e}. Please check the column format.\")\n",
    "    exit()\n",
    "# ****** END OF CLEANING STEP ******\n",
    "\n",
    "# 2. Define Features (X) and Target (y) for Problem A\n",
    "y_class = df_problem_A['attended']\n",
    "X_class = df_problem_A.drop(['attended', 'booking_id'], axis=1)\n",
    "\n",
    "# 3. Identify Feature Types for Problem A\n",
    "numerical_features_class = ['months_as_member', 'weight', 'days_before']\n",
    "categorical_features_class = ['day_of_week', 'time', 'category']\n",
    "\n",
    "# 4. Preprocessing Steps for Problem A\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_class = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features_class),\n",
    "        ('cat', categorical_transformer, categorical_features_class)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 5. Split Data into Training and Testing Sets for Problem A\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n",
    ")\n",
    "print(f\"Data split complete for Problem A: Train set size={len(X_train_class)}, Test set size={len(X_test_class)}\")\n",
    "\n",
    "# 6. Define and Train Models for Problem A (using Pipelines)\n",
    "pipeline_lr = Pipeline(steps=[('preprocessor', preprocessor_class),\n",
    "                              ('classifier', LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000))]) # Increased max_iter\n",
    "\n",
    "pipeline_rf_class = Pipeline(steps=[('preprocessor', preprocessor_class),\n",
    "                                   ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "print(\"\\nTraining Logistic Regression (Problem A)...\")\n",
    "pipeline_lr.fit(X_train_class, y_train_class)\n",
    "print(\"Training Random Forest Classifier (Problem A)...\")\n",
    "pipeline_rf_class.fit(X_train_class, y_train_class)\n",
    "print(\"Model training complete for Problem A.\")\n",
    "\n",
    "# 7. Evaluate Models for Problem A\n",
    "print(\"\\n--- Evaluating Classification Models (Problem A) ---\")\n",
    "\n",
    "# Logistic Regression Evaluation\n",
    "y_pred_lr = pipeline_lr.predict(X_test_class)\n",
    "y_prob_lr = pipeline_lr.predict_proba(X_test_class)[:, 1]\n",
    "print(\"\\nLogistic Regression Performance (Problem A):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_class, y_pred_lr):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test_class, y_prob_lr):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_class, y_pred_lr))\n",
    "\n",
    "# Random Forest Classifier Evaluation\n",
    "y_pred_rf_class = pipeline_rf_class.predict(X_test_class)\n",
    "y_prob_rf_class = pipeline_rf_class.predict_proba(X_test_class)[:, 1]\n",
    "print(\"\\nRandom Forest Classifier Performance (Problem A):\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_class, y_pred_rf_class):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test_class, y_prob_rf_class):.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_class, y_pred_rf_class))\n",
    "\n",
    "\n",
    "# --- Problem B: Optimizing Gym Equipment Utilization (Regression) ---\n",
    "# --- USES data from ./data/problem1.csv BASED ON PROVIDED COLUMN NAMES ---\n",
    "\n",
    "print(\"\\n\\n--- Starting Problem B: Gym Crowdedness Prediction (using ./data/problem1.csv) ---\")\n",
    "\n",
    "# 1. Load Data for Problem B (Regression)\n",
    "data_path_B = './data/problem1.csv' # Updated path\n",
    "try:\n",
    "    df_problem_B = pd.read_csv(data_path_B)\n",
    "    print(f\"Problem B data ({data_path_B}) loaded successfully.\")\n",
    "    # Convert 'date' column to datetime objects\n",
    "    df_problem_B['date'] = pd.to_datetime(df_problem_B['date'])\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: {data_path_B} not found. Please ensure the 'data' folder exists and contains the file.\")\n",
    "    exit()\n",
    "\n",
    "# 2. Define Features (X) and Target (y) for Problem B\n",
    "y_reg = df_problem_B['number_people']\n",
    "X_reg = df_problem_B.drop(['number_people', 'date'], axis=1)\n",
    "\n",
    "# 3. Identify Feature Types for Problem B\n",
    "numerical_features_reg = ['timestamp', 'temperature', 'month', 'hour']\n",
    "categorical_features_reg = ['day_of_week', 'is_weekend', 'is_holiday', 'is_start_of_semester', 'is_during_semester']\n",
    "\n",
    "# 4. Preprocessing Steps for Problem B\n",
    "numerical_transformer_reg = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer_reg = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor_reg = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer_reg, numerical_features_reg),\n",
    "        ('cat', categorical_transformer_reg, categorical_features_reg)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 5. Split Data for Problem B\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"Data split complete for Problem B: Train set size={len(X_train_reg)}, Test set size={len(X_test_reg)}\")\n",
    "\n",
    "# 6. Define and Train Models for Problem B\n",
    "\n",
    "# Model 1: Linear Regression (Baseline)\n",
    "pipeline_linr = Pipeline(steps=[('preprocessor', preprocessor_reg),\n",
    "                                ('regressor', LinearRegression())])\n",
    "\n",
    "# Model 2: Random Forest Regressor\n",
    "pipeline_rf_reg = Pipeline(steps=[('preprocessor', preprocessor_reg),\n",
    "                                  ('regressor', RandomForestRegressor(random_state=42, n_estimators=100))])\n",
    "\n",
    "print(\"\\nTraining Linear Regression (Problem B)...\")\n",
    "pipeline_linr.fit(X_train_reg, y_train_reg)\n",
    "print(\"Training Random Forest Regressor (Problem B)...\")\n",
    "pipeline_rf_reg.fit(X_train_reg, y_train_reg)\n",
    "print(\"Model training complete for Problem B.\")\n",
    "\n",
    "# 7. Evaluate Models for Problem B\n",
    "print(\"\\n--- Evaluating Regression Models (Problem B) ---\")\n",
    "\n",
    "# Linear Regression Evaluation\n",
    "y_pred_linr = pipeline_linr.predict(X_test_reg)\n",
    "rmse_linr = np.sqrt(mean_squared_error(y_test_reg, y_pred_linr))\n",
    "r2_linr = r2_score(y_test_reg, y_pred_linr)\n",
    "print(\"\\nLinear Regression Performance (Problem B):\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse_linr:.4f}\")\n",
    "print(f\"R^2 Score: {r2_linr:.4f}\")\n",
    "\n",
    "# Random Forest Regressor Evaluation\n",
    "y_pred_rf_reg = pipeline_rf_reg.predict(X_test_reg)\n",
    "rmse_rf_reg = np.sqrt(mean_squared_error(y_test_reg, y_pred_rf_reg))\n",
    "r2_rf_reg = r2_score(y_test_reg, y_pred_rf_reg)\n",
    "print(\"\\nRandom Forest Regressor Performance (Problem B):\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse_rf_reg:.4f}\")\n",
    "print(f\"R^2 Score: {r2_rf_reg:.4f}\")\n",
    "\n",
    "# 8. Feature Importance (Example for Random Forest Regressor - Problem B)\n",
    "print(\"\\n--- Feature Importance Analysis (Problem B - Random Forest Regressor) ---\")\n",
    "preprocessor_fitted_reg = pipeline_rf_reg.named_steps['preprocessor']\n",
    "rf_model_reg = pipeline_rf_reg.named_steps['regressor']\n",
    "\n",
    "try:\n",
    "    ohe_feature_names = preprocessor_fitted_reg.named_steps['cat']\\\n",
    "        .named_steps['onehot'].get_feature_names_out(categorical_features_reg)\n",
    "    all_feature_names = numerical_features_reg + ohe_feature_names.tolist()\n",
    "    importances = rf_model_reg.feature_importances_\n",
    "\n",
    "    if len(all_feature_names) == len(importances):\n",
    "        feature_importance_df = pd.DataFrame({'Feature': all_feature_names, 'Importance': importances})\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "        print(\"Top 10 Features influencing gym crowdedness prediction (Problem B):\")\n",
    "        print(feature_importance_df.head(10))\n",
    "    else:\n",
    "        print(f\"Mismatch in feature names ({len(all_feature_names)}) and importances ({len(importances)}). Cannot display feature importance mapping.\")\n",
    "        print(\"Raw Importances:\", importances)\n",
    "except Exception as e:\n",
    "    print(f\"Could not extract feature importances automatically: {e}\")\n",
    "    print(\"Feature importances are available in rf_model_reg.feature_importances_ but matching names requires care.\")\n",
    "\n",
    "print(\"\\n\\n--- Analysis Complete ---\")\n",
    "print(\"Next steps would involve deeper EDA, feature engineering, hyperparameter tuning, model selection, and crucial ethical considerations review.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
